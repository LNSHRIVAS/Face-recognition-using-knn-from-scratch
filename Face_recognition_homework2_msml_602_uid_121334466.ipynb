{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1ynxHOfqBHNCxLvJLJuUoJgB9kfYmSvmP",
      "authorship_tag": "ABX9TyPkAAaygfVs7icqV7n2s1pQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LNSHRIVAS/Face-recognition-using-knn-from-scratch/blob/main/Face_recognition_homework2_msml_602_uid_121334466.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Face recognition: This Notebook is able to recognize a person's face by comparing facial images to that of a known person\n",
        "\n"
      ],
      "metadata": {
        "id": "-SxCHa_sWJkY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import re\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "62ubozkYQezU"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# importing the dataset"
      ],
      "metadata": {
        "id": "e-tYrnn3WkXB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_path = '/content/drive/MyDrive/FaceData'"
      ],
      "metadata": {
        "id": "kFYiNweShE4c"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating an image data loader class which loads the data and extracts the label"
      ],
      "metadata": {
        "id": "w-V_Tk30WpIH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "pKAcojtmm44H"
      },
      "outputs": [],
      "source": [
        "class ImageDataLoader:\n",
        "\n",
        "\n",
        "  def load_image(self, img_path):\n",
        "\n",
        "    img_data = []\n",
        "    img_label = []\n",
        "\n",
        "    for filename in os.listdir(img_path):\n",
        "      pattern = r\"(\\d+)_\\d+\\.png\"              #This line of code extracts the label from the class in the format specified in the text file.\n",
        "      image_path = os.path.join(img_path, filename)\n",
        "      check = re.match(pattern, filename)\n",
        "      if check:\n",
        "        person_id = int(check.group(1))\n",
        "        img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE) / 255.0       #Here we are reading the image file using open cv and normalizing the image by diviing it by 255.0 for every indiviudal pixel.\n",
        "        img_data.append(img.flatten())     # Flattening the image\n",
        "        img_label.append(person_id)\n",
        "\n",
        "    return img_data, img_label"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating the KNN classifier class as specified in the homework assignment document we want to create an 1NN classifier so I named the class as OneNNClassifier."
      ],
      "metadata": {
        "id": "NqP8Of5WXJdh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class OneNNClassifier():\n",
        "\n",
        "  def __init__(self, distance):          # This class takes distance as an input, which can be euclidean and manhattan as specified in the classroom. We can experiment with both of this distances but they moreless yeilds the same results.\n",
        "    self.train_data = None\n",
        "    self.train_labels = None\n",
        "    self.distance = distance\n",
        "\n",
        "  def train(self, train_data, train_labels):  #assigns the train data and labels to the class variables.\n",
        "    self.train_data = train_data\n",
        "    self.train_labels = train_labels\n",
        "\n",
        "  def euclidean_distance(self, x1, x2):       #Function to calcluate the euclidean distance\n",
        "    return np.sqrt(np.sum((x1 - x2) ** 2))\n",
        "\n",
        "  def manhattan_distance(self, x1, x2):        #Function to calculate the manhattan distance\n",
        "    return np.sum(np.abs(x1 - x2))\n",
        "\n",
        "  def predict(self, test_data):               #Fucntion to predict the test dataset\n",
        "\n",
        "  # Predicts the label for each test sample based on the closest (1-nearest) training sample.\n",
        "    predictions = []\n",
        "    for i, test_sample in enumerate(test_data): #We iterate over each test data point and calcuate its distance from the train data points.\n",
        "        if self.distance == 'euclidean':\n",
        "            distances = [self.euclidean_distance(test_sample, train_sample) for train_sample in self.train_data]\n",
        "        elif self.distance == 'manhattan':\n",
        "            distances = [self.manhattan_distance(test_sample, train_sample) for train_sample in self.train_data]\n",
        "\n",
        "        nearest_neighbor_index = np.argmin(distances)   #We get the minimum distance of our test data point from the train data points\n",
        "\n",
        "        # 1-NN step: Assigns the label of the single nearest neighbor as the prediction.\n",
        "\n",
        "        predicted_label = self.train_labels[nearest_neighbor_index]  #we do the predictions\n",
        "        print(f\"Predicted label: {predicted_label}\")\n",
        "\n",
        "        predictions.append(predicted_label)\n",
        "    return predictions\n"
      ],
      "metadata": {
        "id": "aZRTj1rEQxFD"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = ImageDataLoader() #Initializing the class"
      ],
      "metadata": {
        "id": "mSQshIUFQPho"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading the dataset and dividing it into train and test data"
      ],
      "metadata": {
        "id": "ZJVet_s0fEZB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data, label = img.load_image(img_path)  #Loading the data using the ImageDataLoader class we created previously\n",
        "data = np.array(data)  #Converting the data to numpy array\n",
        "label = np.array(label)   #Converting the labels to numpy array\n",
        "randomize_data = np.random.permutation(len(data)) #randomizing the data\n",
        "data = data[randomize_data]\n",
        "label = label[randomize_data]\n",
        "\n",
        "#We are splitting the data as we have to evaluate its accuracy on the test dataset. I am using 80% as train data and 20% of data as testing data.\n",
        "\n",
        "split_ratio = 0.8\n",
        "split_index = int(len(data) * split_ratio)\n",
        "\n",
        "train_data, test_data = data[:split_index], data[split_index:]\n",
        "train_label, test_label = label[:split_index], label[split_index:]"
      ],
      "metadata": {
        "id": "SxIEpHpthqje"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cM2ge4Ii6iCT",
        "outputId": "f375a517-69d8-4b65-ef6f-40c58bbd3cc7"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[21 39 38 11  8 21 29 24 36 23 36  4 11 37 33 36 24 28 16 33 12  1 27 32\n",
            " 15 35 17 31  6 33 10 18  8  5 20  5  8 26 35  7  7 37 17 40 30  1  5 20\n",
            " 32 20 25 12 30 40 38 19 27  3 30  7 37  2 22 25 16 14  6  4 40 22  7 11\n",
            " 35 22  6 35 30 20 26  9]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDyoOS28etLt",
        "outputId": "46ea2063-ec49-45b5-cc37-58a780bed999"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.38823529 0.35294118 0.38039216 ... 0.52941176 0.44313725 0.61960784]\n",
            " [0.34509804 0.33333333 0.34901961 ... 0.45882353 0.45882353 0.45490196]\n",
            " [0.44313725 0.42745098 0.44313725 ... 0.28235294 0.25882353 0.27843137]\n",
            " ...\n",
            " [0.42352941 0.43137255 0.42352941 ... 0.14117647 0.1372549  0.13333333]\n",
            " [0.43921569 0.42745098 0.43529412 ... 0.29019608 0.29411765 0.29019608]\n",
            " [0.43137255 0.42745098 0.43529412 ... 0.36862745 0.34509804 0.35294118]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HmWoQavEevJ1",
        "outputId": "7c786d62-135f-4377-e9d9-c4c0a235d8a2"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[25  9 17 28 19 34  8 11 27 20 25 33  6 15 40 35 33 14 21 13 15 22 34 23\n",
            " 25 34 20 16 15 21  2 26 18  4 35 22 31 39 21 27  8 33 13 38 18 27 27 10\n",
            " 39 15 23  2 16  9  2 39 38 32 10  6 26 24 10 36  4 22 19 10  3 24 19  7\n",
            "  5  9  7  8  4  6  8 19 17 33 26 22  4 23 14 24  5 27 34 24 14  1  7  3\n",
            " 27  6 22 25 15 24  1 26 13  3 34 12 39 32 29  1 22  1 31  9 17 20 12 14\n",
            " 18 16 12 28  1 38 11 37  8 32 28  2  5 36 18 30 23 28 34 17 29 26  5  6\n",
            " 14 29 34 28 36 23 31 27 37 24 16 11 36 13 16 32 38  9  5 33 11  5  3 37\n",
            " 21 24 26  3 21  2 21 37  1 25 18 29 29  4 28  4 35  3 10 15 13 32 12 36\n",
            "  3  7 12 17 37 17 22 26 16 39 21 14  7  8 35 31 19 34 16 24  4 32 29  5\n",
            " 31 10 14 30 20 40 23 25 28 23 20  8 31 14 19 39 39 38 12 20  7 21 15 30\n",
            " 13 28 23 34 40 11  1 29 19 33 10 25 18 13 29 32  9 36 19 30 36 18 13  4\n",
            "  1 31  9  2 15 10 35 17 30 18 12  9 31  2 40  2 14 40 39 37 28 11 17 10\n",
            " 16 25 11 38 15  2 39 23 34 38 13 27 38  6  3 31 13 37 26 12 30 40  6 33\n",
            " 32 29 40  9 19  3 35 18]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DI9q4Crpeg3x",
        "outputId": "bf7cf842-0621-4216-e071-192d3ec9836d"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "320\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_label))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWYRX0AW60RF",
        "outputId": "3192b6a5-d8ff-4ea7-f234-b8771227c18d"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "320\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# We are predicting without the use of cross validation"
      ],
      "metadata": {
        "id": "iGf9Wc_ue8Gx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model  = OneNNClassifier(distance='euclidean')  #\n",
        "model.train(train_data, train_label)\n",
        "predictions = model.predict(test_data)\n",
        "accuracy = np.mean(np.array(predictions) == np.array(test_label))\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJ2xzZOGS2Lq",
        "outputId": "52361ca9-ff9a-4225-91e3-c484d00dfe20"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted label: 21\n",
            "Predicted label: 39\n",
            "Predicted label: 38\n",
            "Predicted label: 11\n",
            "Predicted label: 8\n",
            "Predicted label: 21\n",
            "Predicted label: 29\n",
            "Predicted label: 24\n",
            "Predicted label: 36\n",
            "Predicted label: 23\n",
            "Predicted label: 36\n",
            "Predicted label: 4\n",
            "Predicted label: 11\n",
            "Predicted label: 37\n",
            "Predicted label: 33\n",
            "Predicted label: 36\n",
            "Predicted label: 24\n",
            "Predicted label: 28\n",
            "Predicted label: 16\n",
            "Predicted label: 33\n",
            "Predicted label: 12\n",
            "Predicted label: 1\n",
            "Predicted label: 27\n",
            "Predicted label: 32\n",
            "Predicted label: 15\n",
            "Predicted label: 35\n",
            "Predicted label: 17\n",
            "Predicted label: 31\n",
            "Predicted label: 6\n",
            "Predicted label: 33\n",
            "Predicted label: 10\n",
            "Predicted label: 18\n",
            "Predicted label: 8\n",
            "Predicted label: 5\n",
            "Predicted label: 20\n",
            "Predicted label: 5\n",
            "Predicted label: 8\n",
            "Predicted label: 26\n",
            "Predicted label: 35\n",
            "Predicted label: 7\n",
            "Predicted label: 7\n",
            "Predicted label: 37\n",
            "Predicted label: 17\n",
            "Predicted label: 40\n",
            "Predicted label: 30\n",
            "Predicted label: 1\n",
            "Predicted label: 40\n",
            "Predicted label: 20\n",
            "Predicted label: 32\n",
            "Predicted label: 20\n",
            "Predicted label: 25\n",
            "Predicted label: 12\n",
            "Predicted label: 30\n",
            "Predicted label: 40\n",
            "Predicted label: 38\n",
            "Predicted label: 19\n",
            "Predicted label: 27\n",
            "Predicted label: 3\n",
            "Predicted label: 30\n",
            "Predicted label: 7\n",
            "Predicted label: 37\n",
            "Predicted label: 2\n",
            "Predicted label: 22\n",
            "Predicted label: 25\n",
            "Predicted label: 16\n",
            "Predicted label: 14\n",
            "Predicted label: 6\n",
            "Predicted label: 4\n",
            "Predicted label: 40\n",
            "Predicted label: 22\n",
            "Predicted label: 7\n",
            "Predicted label: 11\n",
            "Predicted label: 35\n",
            "Predicted label: 22\n",
            "Predicted label: 6\n",
            "Predicted label: 35\n",
            "Predicted label: 30\n",
            "Predicted label: 20\n",
            "Predicted label: 26\n",
            "Predicted label: 9\n",
            "Accuracy: 0.9875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cross validation implimentation"
      ],
      "metadata": {
        "id": "4aFHCXWefN4z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class cross_validation():\n",
        "\n",
        "  def __init__(self, k_fold, distance):  #We take in the number of folds required in our case the professor has mentioned to do 5 fold corss-validation\n",
        "    self.k_fold = k_fold\n",
        "    self.distance = distance\n",
        "\n",
        "  def euclidean_distance(self, x1, x2):  #This are just the distances same as we defined in the OneNNClass implimentation\n",
        "    return np.sqrt(np.sum((x1 - x2) ** 2))\n",
        "\n",
        "  def manhattan_distance(self, x1, x2):\n",
        "    return np.sum(np.abs(x1 - x2))\n",
        "\n",
        "  def cross_validation(self, data, label):\n",
        "    fold_size = len(data) // self.k_fold  # This will be 400/5  = 80, we divide the total data length by the value of k which will give us the fold size which than we will use to divide our data.\n",
        "\n",
        "    accuracy_list = []                    #This accuracy list we will use to compute the average accuracy across this 5 fold cross validation.\n",
        "\n",
        "    for k in range(self.k_fold):    #Iterating over each fold\n",
        "      start_index = k * fold_size #This is the starting index from where our data will be used. Forst the first fold 1, 1 * 80, so start index is 80\n",
        "      end_index = (k + 1) * fold_size #This is the end index till were we will use our data. This will be 2 * 80 so end index is 160.\n",
        "\n",
        "      test_data = data[start_index:end_index]  #According to the assingnment here 1 fold data is used for testing data, Test data will be from 80 to 160 in the first fold\n",
        "      test_label = label[start_index:end_index] #This are the respective labels\n",
        "\n",
        "\n",
        "      train_data = np.concatenate([data[:start_index], data[end_index:]])   #Our training data will be like 1 to 79 and form 160 to the rest 400 for first fold and so on...   #This is the training data which is 4 fold and will be used to compare against the test data now.\n",
        "      train_label = np.concatenate([label[:start_index], label[end_index:]])    #This are the respective labels\n",
        "\n",
        "      for i, test_sample in enumerate(test_data):     #Iterating over each test data points to calcuate the predictions.\n",
        "        if self.distance == 'euclidean':\n",
        "            distances = [self.euclidean_distance(test_sample, train_sample) for train_sample in train_data]\n",
        "            nearest_neighbor_index = np.argmin(distances)\n",
        "            predicted_label = train_label[nearest_neighbor_index]\n",
        "        else:\n",
        "            distances = [self.manhattan_distance(test_sample, train_sample) for train_sample in train_data]\n",
        "\n",
        "            # 1-NN step: Find the single nearest neighbor.\n",
        "            nearest_neighbor_index = np.argmin(distances)\n",
        "\n",
        "            # 1-NN prediction: Assign the label of the nearest neighbor to the test sample.\n",
        "            predicted_label = train_label[nearest_neighbor_index]\n",
        "\n",
        "\n",
        "        if predicted_label == test_label[i]:\n",
        "            accuracy_list.append(1)\n",
        "        else:\n",
        "            accuracy_list.append(0)\n",
        "\n",
        "    return accuracy_list\n"
      ],
      "metadata": {
        "id": "blAt7YlJRf7m"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# We have achieved the average accuracy of 97%."
      ],
      "metadata": {
        "id": "D7u8SjrUhjIV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cross_validation_model = cross_validation(k_fold=5, distance='euclidean') #Initilalizing the class cross_validation and passing the value of k = 5 as that is what we were told to do in the assignment doc.\n",
        "accuracy_list = cross_validation_model.cross_validation(data, label) #Passing the data and the labels, which will be handeled by our corss_validation class as it contains the necessary devision of our data based on the k fold method.\n",
        "accuracy = np.mean(accuracy_list) #We have use numpy mean method here to calcuate the average accuracy as it was specified in the assignment to calculate it seperately.\n",
        "print(\"Average Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hp7OOmvBbPWY",
        "outputId": "0f00389a-0914-4d80-fa87-6d928ed86835"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Accuracy: 0.97\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(accuracy_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7zKzpHzObZa9",
        "outputId": "0358d57f-9176-4fe9-a864-77f90d7db06f"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
          ]
        }
      ]
    }
  ]
}